{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import datetime\n",
    "from io import StringIO\n",
    "from new_strategy import Asset\n",
    "from pathlib import Path\n",
    "from new_strategy import Asset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç VIX Debugging:\n",
      "VIX data shape: (8959, 1)\n",
      "VIX date range: 1990-01-02 00:00:00 to 2025-06-27 00:00:00\n",
      "Price date range: 2020-01-01 00:00:00 to 2024-12-31 23:59:00\n",
      "VIX NaN after merge: 550/1827\n",
      "Final VIX NaN: 792000/2630880\n",
      "Bull       2282400\n",
      "Bear        319680\n",
      "Neutral      14400\n",
      "Name: regime_label, dtype: int64\n",
      "‚úÖ Saved processed data to: data/processed/COPPER/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "ASSET = Asset.LIGHT\n",
    "asset_name = ASSET.value\n",
    "\n",
    "# Load raw data\n",
    "raw_path = f\"data/raw/{asset_name}/{asset_name}.csv\"\n",
    "df = pd.read_csv(raw_path)\n",
    "\n",
    "# === Handle non-standard 'Gmt time' column if present ===\n",
    "if 'Gmt time' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['Gmt time'], utc=True)\n",
    "    df.drop(columns=['Gmt time'], inplace=True)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "else:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "df['date'] = df.index.date\n",
    "df.index = df.index.tz_convert(None)\n",
    "df.rename(columns=lambda x: x.strip().lower(), inplace=True)\n",
    "\n",
    "# Load the already merged minute-level data\n",
    "df.index = df.index.tz_localize(None)\n",
    "if 'ATR' in df.columns:\n",
    "    df.drop(columns='ATR', inplace=True)\n",
    "\n",
    "# === Ensure all days are present in index and forward-fill ===\n",
    "start_date = df.index.min().normalize()\n",
    "end_date = df.index.max().normalize()\n",
    "full_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Add missing days with last known values to preserve continuity for rolling metrics\n",
    "df_daily_filled = df.resample('1D').agg({\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last'\n",
    "}).reindex(full_date_range)\n",
    "\n",
    "df_daily_filled.ffill(inplace=True)\n",
    "\n",
    "# Use forward-filled daily OHLC to preserve rolling consistency\n",
    "daily_ohlc = df_daily_filled.copy()\n",
    "\n",
    "#t10y\n",
    "t10y = pd.read_csv(\"data/preprocessing_data/T10YIE.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "t10y.index = t10y.index.tz_localize(None)\n",
    "t10y.rename(columns={t10y.columns[0]: 't10yie'}, inplace=True)\n",
    "t10y = t10y.asfreq('D').ffill()\n",
    "t10y['t10yie'] = t10y['t10yie'].shift(1)\n",
    "daily_ohlc = daily_ohlc.merge(t10y, how='left', left_index=True, right_index=True)\n",
    "\n",
    "#CPI\n",
    "cpi = pd.read_csv(\"data/preprocessing_data/CPIAUCSL.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "cpi.index = cpi.index.tz_localize(None)\n",
    "cpi.rename(columns={cpi.columns[0]: 'cpiaucsl'}, inplace=True)\n",
    "cpi['cpiaucsl'] = cpi['cpiaucsl'].shift(1)\n",
    "cpi = cpi.asfreq('D').ffill()\n",
    "daily_ohlc = daily_ohlc.merge(cpi, how='left', left_index=True, right_index=True)\n",
    "\n",
    "#VIX\n",
    "vix = pd.read_csv(\"data/preprocessing_data/VIX_History.csv\", parse_dates=['date'], index_col='date')\n",
    "vix.index = vix.index.tz_localize(None)\n",
    "vix['vix_close'] = vix['close'].shift(1)\n",
    "vix = vix[['vix_close']]\n",
    "daily_ohlc = daily_ohlc.merge(vix, how='left', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "#DTW\n",
    "dollar = pd.read_csv(\"data/preprocessing_data/DTWEXBGS.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "dollar.index = dollar.index.tz_localize(None)\n",
    "dollar.rename(columns={dollar.columns[0]: 'dtwexbgs'}, inplace=True)\n",
    "dollar['dtwexbgs'] = dollar['dtwexbgs'].shift(1)\n",
    "dollar = dollar.asfreq('D').ffill()\n",
    "daily_ohlc = daily_ohlc.merge(dollar, how='left', left_index=True, right_index=True)\n",
    "\n",
    "#DGS10\n",
    "dgs10 = pd.read_csv(\"data/preprocessing_data/DGS10.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "dgs10.index = dgs10.index.tz_localize(None)\n",
    "dgs10.rename(columns={dgs10.columns[0]: 'dgs10'}, inplace=True)\n",
    "dgs10['dgs10'] = dgs10['dgs10'].shift(1)\n",
    "dgs10 = dgs10.asfreq('D').ffill()\n",
    "daily_ohlc = daily_ohlc.merge(dgs10, how='left', left_index=True, right_index=True)\n",
    "\n",
    "daily_ohlc['prev_close'] = daily_ohlc['close'].shift(1)\n",
    "# Calculate True Range (TR)\n",
    "daily_ohlc['true_range'] = daily_ohlc.apply(\n",
    "    lambda row: max(\n",
    "        row['high'] - row['low'],\n",
    "        abs(row['high'] - row['prev_close']),\n",
    "        abs(row['low'] - row['prev_close'])\n",
    "    ) if pd.notnull(row['prev_close']) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#Calculate 14-day ATR (excluding current day via shift)\n",
    "daily_ohlc['atr_14'] = daily_ohlc['true_range'].rolling(window=14).mean().shift(1)\n",
    "\n",
    "#Calculate moving averages on daily close (also shifted)\n",
    "daily_ohlc['ma_14'] = daily_ohlc['close'].rolling(window=14).mean().shift(1)\n",
    "daily_ohlc['ma_30'] = daily_ohlc['close'].rolling(window=30).mean().shift(1)\n",
    "daily_ohlc['ma_100'] = daily_ohlc['close'].rolling(window=100).mean().shift(1)\n",
    "\n",
    "# Rolling max/min of the daily close\n",
    "daily_ohlc['max_14'] = daily_ohlc['close'].rolling(window=14).max().shift(1)\n",
    "daily_ohlc['min_14'] = daily_ohlc['close'].rolling(window=14).min().shift(1)\n",
    "\n",
    "daily_ohlc['max_30'] = daily_ohlc['close'].rolling(window=30).max().shift(1)\n",
    "daily_ohlc['min_30'] = daily_ohlc['close'].rolling(window=30).min().shift(1)\n",
    "\n",
    "daily_ohlc['max_100'] = daily_ohlc['close'].rolling(window=100).max().shift(1)\n",
    "daily_ohlc['min_100'] = daily_ohlc['close'].rolling(window=100).min().shift(1)\n",
    "\n",
    "\n",
    "\n",
    "# Cumulative max of close price\n",
    "daily_ohlc['static_peak'] = daily_ohlc['close'].cummax()\n",
    "\n",
    "# Static drawdown from that peak\n",
    "daily_ohlc['drawdown_static'] = (\n",
    "    (daily_ohlc['close'] - daily_ohlc['static_peak']) / daily_ohlc['static_peak']\n",
    ").shift(1)\n",
    "\n",
    "daily_ohlc['drawdown_30'] = (\n",
    "    (daily_ohlc['close'] - daily_ohlc['close'].rolling(window=30).max()) \n",
    "    / daily_ohlc['close'].rolling(window=30).max()\n",
    ").shift(1)\n",
    "\n",
    "# Forward-fill daily values into minute-level data\n",
    "df['daily_high'] = daily_ohlc['high'].shift(1).reindex(df.index, method='ffill')\n",
    "df['daily_low'] = daily_ohlc['low'].shift(1).reindex(df.index, method='ffill')\n",
    "df['daily_close'] = daily_ohlc['close'].shift(1).reindex(df.index, method='ffill')\n",
    "df['true_range'] = daily_ohlc['true_range'].shift(1).reindex(df.index, method='ffill')\n",
    "df['atr_14'] = daily_ohlc['atr_14'].reindex(df.index, method='ffill')\n",
    "df['ma_14'] = daily_ohlc['ma_14'].reindex(df.index, method='ffill')\n",
    "df['ma_30'] = daily_ohlc['ma_30'].reindex(df.index, method='ffill')\n",
    "df['ma_100'] = daily_ohlc['ma_100'].reindex(df.index, method='ffill')\n",
    "\n",
    "#Day and Weeknumber\n",
    "df['day_of_week'] = df.index.dayofweek \n",
    "df['week_number'] = df.index.isocalendar().week\n",
    "df['hour_of_day'] = df.index.hour\n",
    "\n",
    "df['max_price_14'] = daily_ohlc['max_14'].reindex(df.index, method='ffill')\n",
    "df['min_price_14'] = daily_ohlc['min_14'].reindex(df.index, method='ffill')\n",
    "\n",
    "df['max_price_30'] = daily_ohlc['max_30'].reindex(df.index, method='ffill')\n",
    "df['min_price_30'] = daily_ohlc['min_30'].reindex(df.index, method='ffill')\n",
    "\n",
    "df['max_price_100'] = daily_ohlc['max_100'].reindex(df.index, method='ffill')\n",
    "df['min_price_100'] = daily_ohlc['min_100'].reindex(df.index, method='ffill')\n",
    "\n",
    "#Drawdown\n",
    "df['drawdown_static'] = daily_ohlc['drawdown_static'].reindex(df.index, method='ffill')\n",
    "df['drawdown_30'] = daily_ohlc['drawdown_30'].reindex(df.index, method='ffill')\n",
    "\n",
    "# Forward-fill T10YIE into minute-level data\n",
    "df['t10yie'] = daily_ohlc['t10yie'].reindex(df.index, method='ffill')\n",
    "#FF CPI\n",
    "df['cpiaucsl'] = daily_ohlc['cpiaucsl'].reindex(df.index, method='ffill')\n",
    "#FF vix\n",
    "df['vix_close'] = daily_ohlc['vix_close'].reindex(df.index, method='ffill')\n",
    "# Debug VIX NaN issues\n",
    "print(f\"\\nüîç VIX Debugging:\")\n",
    "print(f\"VIX data shape: {vix.shape}\")\n",
    "print(f\"VIX date range: {vix.index.min()} to {vix.index.max()}\")\n",
    "print(f\"Price date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"VIX NaN after merge: {daily_ohlc['vix_close'].isna().sum()}/{len(daily_ohlc)}\")\n",
    "print(f\"Final VIX NaN: {df['vix_close'].isna().sum()}/{len(df)}\")\n",
    "#FF Dollar \n",
    "df['dtwexbgs'] = daily_ohlc['dtwexbgs'].reindex(df.index, method='ffill')\n",
    "#FF DGS10\n",
    "df['dgs10'] = daily_ohlc['dgs10'].reindex(df.index, method='ffill')\n",
    "\n",
    "# === Intraday features ===\n",
    "\n",
    "# 1) Short-term returns\n",
    "df['ret_5m']  = df['close'].pct_change(5).shift(1)\n",
    "df['ret_15m'] = df['close'].pct_change(15).shift(1)\n",
    "df['ret_30m'] = df['close'].pct_change(30).shift(1)\n",
    "\n",
    "# 2) Short-term volatility (std of 1m returns)\n",
    "r = df['close'].pct_change()\n",
    "df['vol_5m']  = r.rolling(5,  min_periods=5).std().shift(1)\n",
    "df['vol_15m'] = r.rolling(15, min_periods=15).std().shift(1)\n",
    "df['vol_30m'] = r.rolling(30, min_periods=30).std().shift(1)\n",
    "\n",
    "# 3) Range compression / expansion\n",
    "df['range_5m']  = (df['high'].rolling(5,  min_periods=5).max() - df['low'].rolling(5,  min_periods=5).min()) / df['close']\n",
    "df['range_15m'] = (df['high'].rolling(15, min_periods=15).max() - df['low'].rolling(15, min_periods=15).min()) / df['close']\n",
    "df['range_5m']  = df['range_5m'].shift(1)\n",
    "df['range_15m'] = df['range_15m'].shift(1)\n",
    "\n",
    "# daily_ohlc already lagged ‚Üí no extra shift here\n",
    "daily_ohlc['atr_z_60'] = (daily_ohlc['atr_14'] - daily_ohlc['atr_14'].rolling(60).mean()) / (\n",
    "    daily_ohlc['atr_14'].rolling(60).std() + 1e-12)\n",
    "\n",
    "daily_ohlc['vix_z_60'] = (daily_ohlc['vix_close'] - daily_ohlc['vix_close'].rolling(60).mean()) / (\n",
    "    daily_ohlc['vix_close'].rolling(60).std() + 1e-12)\n",
    "\n",
    "daily_ohlc['ma14_slope_5'] = (daily_ohlc['ma_14'] - daily_ohlc['ma_14'].shift(5)) / (5*(daily_ohlc['atr_14']+1e-12))\n",
    "\n",
    "# ffill to minutes\n",
    "df['atr_z_60']      = daily_ohlc['atr_z_60'].reindex(df.index, method='ffill')\n",
    "df['vix_z_60']      = daily_ohlc['vix_z_60'].reindex(df.index, method='ffill')\n",
    "df['ma14_slope_5']  = daily_ohlc['ma14_slope_5'].reindex(df.index, method='ffill')\n",
    "\n",
    "# intraday (your ret_*, vol_* and range_* are already .shift(1) in your code)\n",
    "eps = 1e-12\n",
    "df['ret30m_voladj']   = df['ret_30m'] / (df['atr_14'] + eps)\n",
    "\n",
    "# pos_in_day_range ‚Äî see block above\n",
    "\n",
    "df['vol_ratio_5_30']  = (df['vol_5m'] / (df['vol_30m'] + eps)).clip(0, 10)\n",
    "df['range15m_voladj'] = (df['range_15m'] / (df['atr_14'] + eps)).clip(0, 10)\n",
    "\n",
    "# cyclical time (no shift needed)\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['hour_of_day']/24.0)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['hour_of_day']/24.0)\n",
    "df['dow_sin']  = np.sin(2*np.pi*df['day_of_week']/7.0)\n",
    "df['dow_cos']  = np.cos(2*np.pi*df['day_of_week']/7.0)\n",
    "\n",
    "# return shape (lag the base series first)\n",
    "r1 = df['close'].pct_change().shift(1)\n",
    "df['skew_30'] = r1.rolling(30).skew()\n",
    "df['kurt_30'] = r1.rolling(30).kurt()\n",
    "\n",
    "# interactions (both sides already lagged/safe)\n",
    "df['vixz_x_ret30m']    = df['vix_z_60'] * df['ret_30m']\n",
    "\n",
    "# breakout flags (use current minute price vs past highs/lows)\n",
    "df['breakout_30_up'] = (df['close'] > df['max_price_30']).astype(int)\n",
    "df['breakout_30_dn'] = (df['close'] < df['min_price_30']).astype(int)\n",
    "\n",
    "g = df.groupby(df.index.date)\n",
    "df['day_hi_so_far'] = g['high'].cummax()\n",
    "df['day_lo_so_far'] = g['low'].cummin()\n",
    "rng = (df['day_hi_so_far'] - df['day_lo_so_far']).replace(0, np.nan)\n",
    "df['pos_in_day_range'] = ((df['close'] - df['day_lo_so_far']) / rng).fillna(0)\n",
    "df.drop(['day_hi_so_far','day_lo_so_far'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Compute HMM Features on Daily Data\n",
    "daily_ohlc['return_raw'] = daily_ohlc['close'].pct_change()\n",
    "daily_ohlc['volatility_raw'] = (\n",
    "    daily_ohlc['close']\n",
    "    .rolling(window=10)\n",
    "    .apply(lambda x: np.mean((x - x.mean())**2))\n",
    ").shift(1)\n",
    "\n",
    "# === Shifted versions for use in model (to avoid lookahead bias) ===\n",
    "daily_ohlc['return'] = daily_ohlc['return_raw'].shift(1)\n",
    "daily_ohlc['volatility'] = daily_ohlc['volatility_raw']\n",
    "\n",
    "df['daily_return'] = daily_ohlc['return'].reindex(df.index, method='ffill')\n",
    "df['daily_volatility'] = daily_ohlc['volatility'].reindex(df.index, method='ffill')\n",
    "\n",
    "# 2. Drop NaNs (due to rolling/shift)\n",
    "hmm_features = daily_ohlc[['return_raw', 'volatility_raw']].dropna()\n",
    "\n",
    "# 3. Fit HMM on ALL data (no slicing)\n",
    "model = GaussianHMM(n_components=3, covariance_type='full', n_iter=75, random_state=42)\n",
    "model.fit(hmm_features)\n",
    "hmm_features['regime'] = model.predict(hmm_features)\n",
    "\n",
    "# 4. Label Regimes (Bull, Bear, Neutral) based on return means\n",
    "regime_means = hmm_features.groupby('regime')['return_raw'].mean().sort_values()\n",
    "regime_mapping = {\n",
    "    regime_means.index[0]: 'Bear',\n",
    "    regime_means.index[1]: 'Neutral',\n",
    "    regime_means.index[2]: 'Bull'\n",
    "}\n",
    "hmm_features['regime_label'] = hmm_features['regime'].map(regime_mapping)\n",
    "\n",
    "# 5. Merge regime info into daily_ohlc\n",
    "daily_ohlc['regime'] = hmm_features['regime']\n",
    "daily_ohlc['regime_label'] = hmm_features['regime_label']\n",
    "\n",
    "# 6. Forward-fill daily regime into minute-level df\n",
    "df['regime'] = daily_ohlc['regime'].reindex(df.index, method='ffill')\n",
    "df['regime_label'] = daily_ohlc['regime_label'].reindex(df.index, method='ffill')\n",
    "\n",
    "#calc avg 30 day return\n",
    "daily_ohlc['avg_return_30d'] = daily_ohlc['return_raw'].rolling(window=30).mean().shift(1)\n",
    "df['avg_return_30d'] = daily_ohlc['avg_return_30d'].reindex(df.index, method='ffill')\n",
    "#Optional: Inspect regime distribution\n",
    "print(df['regime_label'].value_counts())\n",
    "\n",
    "# Overwrite the original file\n",
    "df.index = df.index.tz_localize('UTC')\n",
    "output_path = f\"data/processed/{asset_name}/combined_data.csv\"\n",
    "Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "# === Shift raw volume to avoid lookahead bias ===\n",
    "df['volume_shifted'] = df['volume'].shift(1)\n",
    "df.to_csv(output_path)\n",
    "print(f\"‚úÖ Saved processed data to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\n\\n# === Settings ===\\nasset_name = \"WTI\"  # or \"WTI\"\\npath = f\"data/raw/{asset_name}/combined_data.csv\"\\n\\n# === Load the data ===\\ndf = pd.read_csv(path, parse_dates=[\\'timestamp\\'], index_col=\\'timestamp\\')\\ndf.index = df.index.tz_localize(None)\\n\\n# === Determine date range ===\\nstart_date = df.index.min().normalize()\\nend_date = df.index.max().normalize()\\nfull_range = pd.date_range(start=start_date, end=end_date, freq=\\'D\\')\\n\\n# === Actual calendar days in the data ===\\nactual_days = df.index.normalize().unique()\\nactual_days = pd.DatetimeIndex(actual_days)\\n\\n# === Find missing days ===\\nmissing_days = full_range.difference(actual_days)\\n\\n# === Output ===\\nprint(f\"üìÜ Start date: {start_date.date()}\")\\nprint(f\"üìÜ End date:   {end_date.date()}\")\\nprint(f\"üóìÔ∏è Total calendar days: {len(full_range)}\")\\nprint(f\"üìâ Missing days: {len(missing_days)}\\n\")\\n\\nif len(missing_days) > 0:\\n    print(\"üö´ Missing dates and their weekdays:\")\\n    for day in missing_days:\\n        print(f\" - {day.date()} ({day.strftime(\\'%A\\')})\")\\nelse:\\n    print(\"‚úÖ No missing dates in raw data.\")'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "\n",
    "# === Settings ===\n",
    "asset_name = \"WTI\"  # or \"WTI\"\n",
    "path = f\"data/raw/{asset_name}/combined_data.csv\"\n",
    "\n",
    "# === Load the data ===\n",
    "df = pd.read_csv(path, parse_dates=['timestamp'], index_col='timestamp')\n",
    "df.index = df.index.tz_localize(None)\n",
    "\n",
    "# === Determine date range ===\n",
    "start_date = df.index.min().normalize()\n",
    "end_date = df.index.max().normalize()\n",
    "full_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# === Actual calendar days in the data ===\n",
    "actual_days = df.index.normalize().unique()\n",
    "actual_days = pd.DatetimeIndex(actual_days)\n",
    "\n",
    "# === Find missing days ===\n",
    "missing_days = full_range.difference(actual_days)\n",
    "\n",
    "# === Output ===\n",
    "print(f\"üìÜ Start date: {start_date.date()}\")\n",
    "print(f\"üìÜ End date:   {end_date.date()}\")\n",
    "print(f\"üóìÔ∏è Total calendar days: {len(full_range)}\")\n",
    "print(f\"üìâ Missing days: {len(missing_days)}\\n\")\n",
    "\n",
    "if len(missing_days) > 0:\n",
    "    print(\"üö´ Missing dates and their weekdays:\")\n",
    "    for day in missing_days:\n",
    "        print(f\" - {day.date()} ({day.strftime('%A')})\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing dates in raw data.\")\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4131570aad7ff77d93c6be89cfb61a61d96547c15666b9d6a932bac1ad3bd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
