{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from new_strategy import Asset, BetSizingMethod, get_bet_sizing\n",
    "import nbimporter\n",
    "from backtest import Backtest\n",
    "from meta_strategy import MetaLabelingStrategy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# ---------------------- MetaModelHandler ---------------------- #\n",
    "class MetaModelHandler:\n",
    "    def __init__(self):\n",
    "        self.long_model = None\n",
    "        self.short_model = None\n",
    "        self.long_scaler = None\n",
    "        self.short_scaler = None\n",
    "        self.feature_cols = []\n",
    "\n",
    "    def train(self, trades_df: pd.DataFrame, feature_cols: list):\n",
    "        self.feature_cols = feature_cols\n",
    "        trades_df = trades_df.dropna(subset=feature_cols + ['meta_label'])\n",
    "\n",
    "        long_trades = trades_df[trades_df['direction'] == 'long']\n",
    "        short_trades = trades_df[trades_df['direction'] == 'short']\n",
    "\n",
    "        def preprocess(df):\n",
    "            X = df[feature_cols]\n",
    "            y = df['meta_label']\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            return X_scaled, y, scaler\n",
    "\n",
    "        X_long, y_long, self.long_scaler = preprocess(long_trades)\n",
    "        X_short, y_short, self.short_scaler = preprocess(short_trades)\n",
    "\n",
    "        self.long_model = CalibratedClassifierCV(LogisticRegression(), method='sigmoid').fit(X_long, y_long)\n",
    "        self.short_model = CalibratedClassifierCV(LogisticRegression(), method='sigmoid').fit(X_short, y_short)\n",
    "\n",
    "        \"\"\"\"\"\n",
    "        self.long_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "        self.short_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "        self.long_model.fit(X_long, y_long)\n",
    "        self.short_model.fit(X_short, y_short)\"\"\"\n",
    "\n",
    "\n",
    "    def is_trade_approved(self, features: dict, direction: str, threshold: float = 0.5) -> bool:\n",
    "    # Clean NaNs or infinities in input features\n",
    "        cleaned = {}\n",
    "        for k in self.feature_cols:\n",
    "            val = features.get(k, 0)\n",
    "            if pd.isna(val) or val in [np.inf, -np.inf]:\n",
    "                cleaned[k] = 0  # replace invalid values with 0 (or another neutral default)\n",
    "            else:\n",
    "                cleaned[k] = val\n",
    "\n",
    "        df = pd.DataFrame([cleaned])[self.feature_cols]\n",
    "\n",
    "        if direction == 'long':\n",
    "            X = self.long_scaler.transform(df)\n",
    "            prob = self.long_model.predict_proba(X)[0, 1]\n",
    "        else:\n",
    "            X = self.short_scaler.transform(df)\n",
    "            prob = self.short_model.predict_proba(X)[0, 1]\n",
    "\n",
    "        \n",
    "        print(f\"[MetaModel] Direction: {direction}, Prob: {prob:.3f}, Threshold: {threshold}, Approved: {prob >= threshold}\")\n",
    "\n",
    "        return prob >= threshold\n",
    "\n",
    "\n",
    "# ---------------------- Helper Functions ---------------------- #\n",
    "def train_test_split_time_series(trades_df: pd.DataFrame, test_size: float = 0.3):\n",
    "    trades_df = trades_df.sort_values('entry_time')\n",
    "    split_idx = int(len(trades_df) * (1 - test_size))\n",
    "    return trades_df.iloc[:split_idx], trades_df.iloc[split_idx:]\n",
    "\n",
    "def load_meta_labeled_data(asset: Asset, method: BetSizingMethod, test_size=0.3):\n",
    "    meta_path = Path(f\"data/metalabels/meta_labels_{asset.value}_{method.value}.csv\")\n",
    "    if not meta_path.exists():\n",
    "        raise FileNotFoundError(f\"Meta-labeled file not found: {meta_path}\")\n",
    "\n",
    "    df = pd.read_csv(meta_path, parse_dates=[\"entry_time\", \"exit_time\"])\n",
    "    df = df.dropna(subset=[\"meta_label\"])\n",
    "    df = df.sort_values(\"entry_time\")\n",
    "    split_idx = int(len(df) * (1 - test_size))\n",
    "    return df.iloc[:split_idx], df.iloc[split_idx:]\n",
    "\n",
    "def train_meta_model(train_df: pd.DataFrame, feature_cols: list) -> MetaModelHandler:\n",
    "    meta_model = MetaModelHandler()\n",
    "    meta_model.train(train_df, feature_cols)\n",
    "    return meta_model\n",
    "\n",
    "# ---------------------- Run Backtest ---------------------- #\n",
    "def run_metalabel_backtest(asset: Asset, method: BetSizingMethod, feature_cols: list):\n",
    "    # Load raw price data\n",
    "    price_data_path = Path(f\"data/processed/{asset.value}/combined_data.csv\")\n",
    "    price_data = pd.read_csv(price_data_path, index_col=\"timestamp\", parse_dates=True)\n",
    "\n",
    "    # Load and split meta-labeled data\n",
    "    train_df, test_df = load_meta_labeled_data(asset, method)\n",
    "    print(\"ðŸ“Š Diagnostics on training set\")\n",
    "    print(\"train_df columns:\", train_df.columns.tolist())\n",
    "    print(\"Unique directions in train_df:\", train_df['direction'].unique() if 'direction' in train_df else \"Missing 'direction' column\")\n",
    "    print(\"Rows before dropna:\", len(train_df))\n",
    "    missing_summary = train_df[feature_cols + ['meta_label']].isnull().sum()\n",
    "    print(\"Missing values per feature:\\n\", missing_summary)\n",
    "\n",
    "    test_start = test_df['entry_time'].min()\n",
    "\n",
    "    # Train meta model on training data\n",
    "    meta_handler = train_meta_model(train_df, feature_cols)\n",
    "\n",
    "    # Restrict price data to test period (to simulate live trading post-training)\n",
    "    price_data = price_data[price_data.index >= test_start]\n",
    "\n",
    "    # Get bet sizing method\n",
    "    past_returns = price_data['close'].pct_change().dropna()\n",
    "    bet_sizing = get_bet_sizing(method, past_returns)\n",
    "\n",
    "    # Run strategy with meta-model\n",
    "    strategy = MetaLabelingStrategy(price_data, asset.value, bet_sizing, method, meta_model_handler=meta_handler,feature_cols=feature_cols)\n",
    "    strategy.generate_signals()\n",
    "    strategy.simulate_trades()\n",
    "\n",
    "    # Backtest results\n",
    "    backtest = Backtest(strategy)\n",
    "    backtest.run_analysis()\n",
    "    backtest.print_summary()\n",
    "    print(f\"\\nðŸ§® Total Trades Rejected by Meta-Model: {strategy.rejected_trades}\")\n",
    "\n",
    "    # Save filtered trades to CSV for inspection\n",
    "    output_dir = Path(\"data/results_metalabel\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    filename = f\"trades_meta_filtered_{asset.value}_{method.value}.csv\"\n",
    "    filtered_trades_df = strategy.get_trade_data()\n",
    "    filtered_trades_df.to_csv(output_dir / filename, index=False)\n",
    "\n",
    "    logging.info(f\"Saved filtered trades to: {output_dir / filename}\")\n",
    "\n",
    "# --- Print key performance metrics ---\n",
    "    metrics = backtest.results['sessions']\n",
    "    print(f\"\\n--- Meta-Filtered Performance Summary ({asset.value}, {method.value}) ---\")\n",
    "    for session, result in metrics.items():\n",
    "        m = result['metrics']\n",
    "        print(f\"\\n[{session.upper()} SESSION]\")\n",
    "        print(f\"Total PnL: ${m.total_pnl:,.2f}\")\n",
    "        print(f\"Return: {m.total_return_pct:.2f}%\")\n",
    "        print(f\"Sharpe Ratio: {m.sharpe:.2f}\" if m.sharpe else \"Sharpe: n/a\")\n",
    "        print(f\"Win Rate: {m.win_rate:.2%}\")\n",
    "        print(f\"Max Drawdown: {m.max_drawdown_pct:.2f}%\")\n",
    "\n",
    "\n",
    "# ---------------------- Main Entry ---------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    asset = Asset.XAUUSD\n",
    "    method = BetSizingMethod.FIXED\n",
    "    feature_cols = [\"atr_14\", \"attempt\", \"duration_minutes\", \"ref_close\"]\n",
    "\n",
    "    run_metalabel_backtest(asset, method, feature_cols)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4131570aad7ff77d93c6be89cfb61a61d96547c15666b9d6a932bac1ad3bd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
