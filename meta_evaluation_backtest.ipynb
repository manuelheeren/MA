{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import io\n",
    "import sys\n",
    "import logging\n",
    "from new_strategy import TradingStrategy, Asset, BetSizingMethod, get_bet_sizing\n",
    "from meta_strategy import MetaLabelingStrategy\n",
    "import nbimporter\n",
    "from backtest import Backtest\n",
    "from add_features import generate_meta_labeled_data, merge_with_raw_features\n",
    "from metalabel_backtest import MetaModelHandler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 23:06:58,361 - INFO - Strategy initialized for BTCUSD using FixedFractionalBetSizing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data Split:\n",
      "  → Training: 2104704 samples (80.0%)\n",
      "  → Testing:  526176 samples (20.0%)\n",
      "\n",
      "🔄 Running training phase...\n"
     ]
    }
   ],
   "source": [
    "def split_price_data(price_data: pd.DataFrame, split_ratio: float = 0.7):\n",
    "    split_idx = int(len(price_data) * split_ratio)\n",
    "    return price_data.iloc[:split_idx], price_data.iloc[split_idx:]\n",
    "\n",
    "def run_training_phase(asset: Asset, method: BetSizingMethod, price_data: pd.DataFrame):\n",
    "    # Run base strategy\n",
    "    past_returns = price_data['close'].pct_change().dropna()\n",
    "    bet_sizing = get_bet_sizing(method, past_returns)\n",
    "    \n",
    "    strategy = TradingStrategy(price_data, asset.value, bet_sizing, method)\n",
    "    strategy.generate_signals()\n",
    "    strategy.simulate_trades()\n",
    "    \n",
    "    trade_df = strategy.get_trade_data()\n",
    "    labeled = generate_meta_labeled_data(trade_df)\n",
    "    #labeled_with_features = merge_with_raw_features(labeled, asset.value)\n",
    "    labeled_with_features = labeled\n",
    "    \n",
    "    print(labeled_with_features.columns)\n",
    "    return labeled_with_features\n",
    "\n",
    "def train_meta_model(train_df: pd.DataFrame, \n",
    "                     long_feature_cols: list, short_feature_cols: list,\n",
    "                     asset, method) -> MetaModelHandler:\n",
    "    \"\"\"\n",
    "    Modified to use only training data with cross-validation instead of separate validation set.\n",
    "    \"\"\"\n",
    "    # Shift rolling metrics to avoid lookahead bias\n",
    "    rolling_cols = [\n",
    "        'rolling_f1', 'rolling_accuracy', 'rolling_precision', 'rolling_recall',\n",
    "        'n_total_seen', 'n_window_obs'\n",
    "    ]\n",
    "    for col in rolling_cols:\n",
    "        if col in train_df.columns:\n",
    "            train_df[col] = train_df.groupby('session')[col].shift(1)\n",
    "\n",
    "    # Remove any 'set' column if it exists\n",
    "    if 'set' in train_df.columns:\n",
    "        train_df = train_df.drop('set', axis=1)\n",
    "\n",
    "    meta_model = MetaModelHandler()\n",
    "    meta_model.train(\n",
    "        trades_df=train_df,  # Only pass training data\n",
    "        long_feature_cols=long_feature_cols,\n",
    "        short_feature_cols=short_feature_cols,\n",
    "        asset_name=asset.value,\n",
    "        method_name=method.value,\n",
    "    )\n",
    "\n",
    "    return meta_model\n",
    "\n",
    "\n",
    "def run_parallel_evaluation(asset, method, test_price_data, signals, meta_model, feature_cols):\n",
    "    past_returns = test_price_data['close'].pct_change().dropna()\n",
    "    bet_sizing = get_bet_sizing(method, past_returns)\n",
    "\n",
    "    #  First, initialize Meta strategy to access feature-enriched data\n",
    "    meta_strategy = MetaLabelingStrategy(\n",
    "        test_price_data.copy(), asset.value, bet_sizing, method,\n",
    "        meta_model_handler=meta_model\n",
    "    )\n",
    "    feature_data = meta_strategy.data.copy()\n",
    "\n",
    "    #  Use feature_data for both strategies\n",
    "    baseline = TradingStrategy(feature_data.copy(), asset.value, bet_sizing, method)\n",
    "    baseline.trade_signals = signals\n",
    "\n",
    "    filtered = MetaLabelingStrategy(feature_data.copy(), asset.value, bet_sizing, method, meta_model_handler=meta_model,feature_cols=feature_cols)\n",
    "    filtered.trade_signals = signals\n",
    "\n",
    "    print(\"\\n📊 Baseline features in .data:\")\n",
    "    print(baseline.data.columns.tolist())\n",
    "\n",
    "    print(\"\\n📊 Filtered features in .data:\")\n",
    "    print(filtered.data.columns.tolist())\n",
    "    print(\"\\n🕒 Baseline index:\", baseline.data.index.name, baseline.data.index.dtype)\n",
    "    print(\"🕒 Filtered index:\", filtered.data.index.name, filtered.data.index.dtype)\n",
    "\n",
    "    baseline.simulate_trades()\n",
    "    filtered.simulate_trades()\n",
    "\n",
    "    return baseline, filtered\n",
    "\n",
    "def compare_backtests(baseline: TradingStrategy, filtered: MetaLabelingStrategy, asset: Asset, method: BetSizingMethod):\n",
    "    def capture_regime_stats(strategy, name):\n",
    "        buffer = io.StringIO()\n",
    "        sys.stdout = buffer\n",
    "        print(f\"\\n🔹 {name} Strategy:\")\n",
    "\n",
    "        df = strategy.get_trade_data()\n",
    "\n",
    "        if 'regime_label' not in df.columns or 'pnl' not in df.columns:\n",
    "            print(\"Required columns not found in trade data.\")\n",
    "        else:\n",
    "            grouped = df.groupby('regime_label')\n",
    "\n",
    "            for regime, group in grouped:\n",
    "                trades = len(group)\n",
    "                avg_pnl = group['pnl'].mean()\n",
    "                total_pnl = group['pnl'].sum()\n",
    "                wins = (group['pnl'] > 0).sum()\n",
    "                winrate = wins / trades if trades > 0 else 0\n",
    "\n",
    "                print(f\"  {regime}: Trades = {trades}, \"\n",
    "                      f\"Avg PnL = {avg_pnl:.2f}, Total PnL = {total_pnl:.2f}, \"\n",
    "                      f\"Win Rate = {winrate:.2%}\")\n",
    "\n",
    "        sys.stdout = sys.__stdout__\n",
    "        return buffer.getvalue()\n",
    "    \n",
    "    print(\"\\n[BASELINE]\")\n",
    "    baseline_bt = Backtest(baseline)\n",
    "    baseline_bt.run_analysis()\n",
    "    baseline_buffer = io.StringIO()\n",
    "    sys.stdout = baseline_buffer\n",
    "    baseline_bt.print_summary()\n",
    "    sys.stdout = sys.__stdout__\n",
    "    baseline_summary = baseline_buffer.getvalue()\n",
    "    print(baseline_summary)\n",
    "\n",
    "    print(\"\\n[META-FILTERED]\")\n",
    "    filtered_bt = Backtest(filtered)\n",
    "    filtered_bt.run_analysis()\n",
    "    filtered_buffer = io.StringIO()\n",
    "    sys.stdout = filtered_buffer\n",
    "    filtered_bt.print_summary()\n",
    "    sys.stdout = sys.__stdout__\n",
    "    filtered_summary = filtered_buffer.getvalue()\n",
    "    print(filtered_summary)\n",
    "\n",
    "    print(f\"\\nTrades Rejected by Meta-Model: {filtered.rejected_trades}\")\n",
    "\n",
    "    output_dir = \"results_metalabel\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    asset_name = asset.value.lower()\n",
    "    method_name = method.value.lower()\n",
    "\n",
    "    baseline_csv = f\"baseline_{asset_name}_{method_name}.csv\"\n",
    "    filtered_csv = f\"filtered_{asset_name}_{method_name}.csv\"\n",
    "    baseline_txt = f\"baseline_{asset_name}_{method_name}.txt\"\n",
    "    filtered_txt = f\"filtered_{asset_name}_{method_name}.txt\"\n",
    "\n",
    "    baseline.get_trade_data().to_csv(os.path.join(output_dir, baseline_csv), index=False)\n",
    "    filtered.get_trade_data().to_csv(os.path.join(output_dir, filtered_csv), index=False)\n",
    "\n",
    "    \"\"\"with open(os.path.join(output_dir, baseline_txt), \"w\") as f:\n",
    "        f.write(baseline_summary)\n",
    "\n",
    "    with open(os.path.join(output_dir, filtered_txt), \"w\") as f:\n",
    "        f.write(filtered_summary)\"\"\"\n",
    "    \n",
    "        # Run and print regime comparisons\n",
    "    print(\"\\n📈 Regime Comparison\")\n",
    "    regime_baseline = capture_regime_stats(baseline, \"Baseline\")\n",
    "    regime_filtered = capture_regime_stats(filtered, \"Meta-Filtered\")\n",
    "\n",
    "    print(regime_baseline)\n",
    "    print(regime_filtered)\n",
    "\n",
    "    \"\"\"# Append to the already existing summary files\n",
    "    with open(baseline_txt, \"a\") as f:\n",
    "        f.write(\"\\n\\n=== Regime Analysis ===\\n\")\n",
    "        f.write(regime_baseline)\n",
    "\n",
    "    with open(filtered_txt, \"a\") as f:\n",
    "        f.write(\"\\n\\n=== Regime Analysis ===\\n\")\n",
    "        f.write(regime_filtered)\"\"\"\n",
    "\n",
    "    print(f\"\\n✅ CSVs saved to: {output_dir}\")\n",
    "    print(f\" - {baseline_csv}\")\n",
    "    print(f\" - {filtered_csv}\")\n",
    "    print(f\"\\n✅ Summaries saved to:\")\n",
    "    print(f\" - {baseline_txt}\")\n",
    "    print(f\" - {filtered_txt}\")\n",
    "\n",
    "def evaluate_backtest_and_regimes(\n",
    "    baseline_path: str,\n",
    "    filtered_path: str,\n",
    "    txt_output_path: str = \"results_metalabel/comparison/evaluation_summary.txt\"\n",
    "):\n",
    "    buffer = io.StringIO()\n",
    "    sys.stdout = buffer  # Redirect print to buffer\n",
    "\n",
    "    print(\"\\n📊 Evaluation from Final CSVs\")\n",
    "\n",
    "    def compute_backtest_kpis(df: pd.DataFrame, label: str):\n",
    "        print(f\"\\n📈 {label} Backtest Summary (Per Session Evaluation)\")\n",
    "\n",
    "        df = df[df['position_size'] > 0]\n",
    "\n",
    "        if 'pnl' not in df.columns or 'session' not in df.columns:\n",
    "            print(\"❌ Missing required columns ('pnl', 'session').\")\n",
    "            return\n",
    "\n",
    "        session_stats = []\n",
    "\n",
    "        for session, group in df.groupby(\"session\"):\n",
    "            group = group.sort_values(\"exit_time\")\n",
    "\n",
    "            if group.empty:\n",
    "                continue\n",
    "\n",
    "            # Build capital curve on actual trade exits\n",
    "            capital = 100_000  # consistent with old method\n",
    "            capital_curve = []\n",
    "\n",
    "            for pnl in group['pnl']:\n",
    "                capital += pnl\n",
    "                capital_curve.append(capital)\n",
    "\n",
    "            group = group.copy()\n",
    "            group['capital_curve'] = capital_curve\n",
    "            returns = pd.Series(capital_curve).pct_change().dropna()\n",
    "\n",
    "            # Sharpe: based on trading days only\n",
    "            if len(returns) >= 2:\n",
    "                mean_return = returns.mean()\n",
    "                vol = returns.std()\n",
    "                sharpe = (mean_return / vol) * np.sqrt(252) if vol > 0 else 0\n",
    "            else:\n",
    "                sharpe = 0\n",
    "\n",
    "            # Max drawdown from capital curve\n",
    "            cumulative = pd.Series(capital_curve).cummax()\n",
    "            drawdown = (cumulative - capital_curve) / cumulative\n",
    "            max_drawdown = drawdown.max()\n",
    "\n",
    "            wins = (group['pnl'] > 0).sum()\n",
    "            losses = (group['pnl'] <= 0).sum()\n",
    "            win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "\n",
    "            total_pnl = group[\"pnl\"].sum()\n",
    "            final_capital = capital_curve[-1]\n",
    "\n",
    "            session_stats.append({\n",
    "                \"session\": session,\n",
    "                \"total_pnl\": total_pnl,\n",
    "                \"final_capital\": final_capital,\n",
    "                \"win_rate\": win_rate,\n",
    "                \"sharpe\": sharpe,\n",
    "                \"max_drawdown\": max_drawdown,\n",
    "                \"trades\": len(group)\n",
    "            })\n",
    "\n",
    "            print(f\"\\n🔹 Session: {session}\")\n",
    "            print(f\"  Final Capital: ${final_capital:,.2f}\")\n",
    "            print(f\"  Total PnL:     ${total_pnl:,.2f}\")\n",
    "            print(f\"  Win Rate:      {win_rate:.2%} ({wins}W / {losses}L)\")\n",
    "            print(f\"  Max Drawdown:  {max_drawdown:.2%}\")\n",
    "            print(f\"  Sharpe Ratio:  {sharpe:.2f}\")\n",
    "            print(f\"  Total Trades:  {len(group)}\")\n",
    "\n",
    "        # Optional combined stats\n",
    "        combined_pnl = sum(s[\"total_pnl\"] for s in session_stats)\n",
    "        print(f\"\\n📊 Combined PnL across all sessions: ${combined_pnl:,.2f}\")\n",
    "\n",
    "\n",
    "    def compute_regime_stats(df: pd.DataFrame, label: str):\n",
    "        print(f\"\\n📊 {label} Regime Breakdown by Session\")\n",
    "\n",
    "        if \"regime_label\" not in df.columns or \"pnl\" not in df.columns or \"session\" not in df.columns:\n",
    "            print(\"❌ Missing required columns ('regime_label', 'pnl', or 'session').\")\n",
    "            return\n",
    "\n",
    "        session_groups = df.groupby(\"session\")\n",
    "        for session, session_df in session_groups:\n",
    "            print(f\"\\n🔹 Session: {session}\")\n",
    "            regime_groups = session_df.groupby(\"regime_label\")\n",
    "            for regime, group in regime_groups:\n",
    "                trades = len(group)\n",
    "                avg_pnl = group[\"pnl\"].mean()\n",
    "                total_pnl = group[\"pnl\"].sum()\n",
    "                wins = (group[\"pnl\"] > 0).sum()\n",
    "                win_rate = wins / trades if trades > 0 else 0\n",
    "\n",
    "                print(f\"  - Regime: {regime}\")\n",
    "                print(f\"    Trades:    {trades}\")\n",
    "                print(f\"    Avg PnL:   ${avg_pnl:.2f}\")\n",
    "                print(f\"    Total PnL: ${total_pnl:.2f}\")\n",
    "                print(f\"    Win Rated:  {win_rate:.2%}\")\n",
    "\n",
    "\n",
    "    # === Load CSVs ===\n",
    "    baseline_df = pd.read_csv(baseline_path, parse_dates=[\"entry_time\", \"exit_time\"])\n",
    "    filtered_df = pd.read_csv(filtered_path, parse_dates=[\"entry_time\", \"exit_time\"])\n",
    "\n",
    "    # === Compute Metrics ===\n",
    "    compute_backtest_kpis(baseline_df, \"Baseline\")\n",
    "    compute_regime_stats(baseline_df, \"Baseline\")\n",
    "\n",
    "    compute_backtest_kpis(filtered_df, \"Meta-Filtered\")\n",
    "    compute_regime_stats(filtered_df, \"Meta-Filtered\")\n",
    "\n",
    "    # === Write output to TXT file ===\n",
    "    sys.stdout = sys.__stdout__  # Restore stdout\n",
    "    with open(txt_output_path, \"w\") as f:\n",
    "        f.write(buffer.getvalue())\n",
    "\n",
    "    print(f\"\\n✅ Full evaluation written to: {txt_output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "    asset = Asset.BTCUSD\n",
    "    method = BetSizingMethod.FIXED\n",
    "\n",
    "    #long_feature_cols = [\"session_code\",\"open\",\"attempt\",\"rolling_f1\",\"rolling_accuracy\",\"ret30m_voladj\",\"ma14_slope_5\",\"pos_in_day_range\",\"vol_ratio_5_30\",\"range15m_voladj\",\"drawdown_30\",\"daily_volatility\",\"avg_return_30d\",\"hour_sin\",\"hour_cos\",\"dow_sin\",\"dow_cos\",\"volume_shifted\",\"breakout_30_up\",\"breakout_30_dn\",\"t10yie\",\"dgs10\",\"dtwexbgs\"]\n",
    "    #short_feature_cols = [\"session_code\",\"open\",\"attempt\",\"rolling_f1\",\"rolling_accuracy\",\"ret30m_voladj\",\"ma14_slope_5\",\"pos_in_day_range\",\"vol_ratio_5_30\",\"range15m_voladj\",\"drawdown_30\",\"daily_volatility\",\"avg_return_30d\",\"hour_sin\",\"hour_cos\",\"dow_sin\",\"dow_cos\",\"volume_shifted\",\"breakout_30_up\",\"breakout_30_dn\",\"t10yie\",\"dgs10\",\"dtwexbgs\"]\n",
    "\n",
    "    long_feature_cols = [\"attempt\", \"pos_in_day_range\", \"daily_volatility\", \"rolling_f1\", \"volume_shifted\", \"atr_z_60\", \"dgs10\", \"range15m_voladj\", \"ret_30m\", \"vol_15m\", \"ma14_slope_5\", \"dtwexbgs\", \"range_15m\", \"open\", \"avg_return_30d\",\"ret30m_voladj\",\"atr_14\",\"drawdown_30\",\"vol_30m\",\"hour_of_day\",\n",
    "]\n",
    "\n",
    "    short_feature_cols = [\"attempt\", \"ret30m_voladj\", \"avg_return_30d\", \"ret_30m\", \"range15m_voladj\", \"ma14_slope_5\", \"volume_shifted\", \"atr_z_60\", \"cpiaucsl\", \"dtwexbgs\", \"open\", \"rolling_f1\", \"drawdown_30\", \"pos_in_day_range\", \"vol_ratio_5_30\",\"vol_ratio_5_30\",\"daily_volatility\",\"vol_5m\",\"atr_14\",\"ma_14\",\"vol_15m\"\n",
    "]\n",
    "\n",
    "    price_path = Path(f\"data/processed/{asset.value}/combined_data.csv\")\n",
    "    price_data = pd.read_csv(price_path, index_col='timestamp', parse_dates=True)\n",
    "\n",
    "    # Modified split: Only train and test (no validation set)\n",
    "    n = len(price_data)\n",
    "    train_size = int(n * 0.8)  # Increased from 0.6 to 0.8 since we're not using validation\n",
    "\n",
    "    train_data = price_data.iloc[:train_size]\n",
    "    test_data = price_data.iloc[train_size:]\n",
    "\n",
    "    print(f\"📊 Data Split:\")\n",
    "    print(f\"  → Training: {len(train_data)} samples ({len(train_data)/len(price_data):.1%})\")\n",
    "    print(f\"  → Testing:  {len(test_data)} samples ({len(test_data)/len(price_data):.1%})\")\n",
    "\n",
    "\n",
    "    # Training - only on training data, no separate validation\n",
    "    print(\"\\n🔄 Running training phase...\")\n",
    "    train_trades = run_training_phase(asset, method, train_data)\n",
    "\n",
    "    # Clean features\n",
    "    all_features = list(set(long_feature_cols + short_feature_cols))\n",
    "    train_trades_cleaned = train_trades.replace([np.inf, -np.inf], np.nan).dropna(subset=all_features)\n",
    "\n",
    "    train_trades_cleaned.to_csv(\"results_metalabel/train_data_debug.csv\", index=False)\n",
    "    print(\"✅ Training data saved to results_metalabel/train_data_debug.csv\")\n",
    "\n",
    "    # Train meta-model using cross-validation (no separate validation set)\n",
    "    print(\"\\n🤖 Training meta-model with cross-validation...\")\n",
    "    meta_model = train_meta_model(\n",
    "    train_trades_cleaned,  # Only pass training data\n",
    "    long_feature_cols,\n",
    "    short_feature_cols,\n",
    "    asset,\n",
    "    method\n",
    ")\n",
    "\n",
    "    # Reuse signals\n",
    "    signal_gen = TradingStrategy(test_data.copy(), asset.value, get_bet_sizing(method), method)\n",
    "    signal_gen.generate_signals()\n",
    "    shared_signals = signal_gen.trade_signals\n",
    "\n",
    "    print(\"\\n🔍 Entry Time Check (from shared_signals dict):\")\n",
    "    print(\"Type:\", type(shared_signals))\n",
    "    print(\"Keys in shared_signals:\", list(shared_signals.keys()))\n",
    "\n",
    "    # Try to peek at the first signal (depending on structure)\n",
    "    first_key = next(iter(shared_signals))\n",
    "    first_signal_list = shared_signals[first_key]\n",
    "    first_signal = first_signal_list[0]  # Get the first signal from the list\n",
    "    print(\"Type of entry_time:\", type(first_signal['entry_time']))\n",
    "\n",
    "    # Evaluation\n",
    "    base_strat, filtered_strat = run_parallel_evaluation(\n",
    "        asset, method, test_data, shared_signals, meta_model, all_features\n",
    "    )\n",
    "\n",
    "    # Compare\n",
    "    compare_backtests(base_strat, filtered_strat, asset, method)\n",
    "    evaluate_backtest_and_regimes(\n",
    "    baseline_path=f\"results_metalabel/baseline_{asset.value.lower()}_{method.value.lower()}.csv\",\n",
    "    filtered_path=f\"results_metalabel/filtered_{asset.value.lower()}_{method.value.lower()}.csv\",\n",
    "    txt_output_path=f\"results_metalabel/comparison/evaluation_{asset.value.lower()}_{method.value.lower()}.txt\"\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4131570aad7ff77d93c6be89cfb61a61d96547c15666b9d6a932bac1ad3bd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
