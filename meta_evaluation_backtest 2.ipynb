{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import sys\n",
    "import logging\n",
    "from new_strategy import TradingStrategy, Asset, BetSizingMethod, get_bet_sizing\n",
    "from meta_strategy import MetaLabelingStrategy\n",
    "import nbimporter\n",
    "from backtest import Backtest\n",
    "from add_features import generate_meta_labeled_data, merge_with_raw_features\n",
    "from metalabel_backtest import MetaModelHandler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 12:41:17,285 - INFO - Strategy initialized for GAS using FixedFractionalBetSizing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb Zelle 2\u001b[0m in \u001b[0;36m<cell line: 279>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=291'>292</a>\u001b[0m train_data, test_data \u001b[39m=\u001b[39m split_price_data(price_data)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=293'>294</a>\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=294'>295</a>\u001b[0m train_trades \u001b[39m=\u001b[39m run_training_phase(asset, method, train_data)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=296'>297</a>\u001b[0m \u001b[39m#clean_features = train_trades[feature_cols].replace([np.inf, -np.inf], np.nan).dropna()\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=297'>298</a>\u001b[0m \u001b[39m#train_trades_cleaned = train_trades.loc[clean_features.index]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=298'>299</a>\u001b[0m all_features \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(long_feature_cols \u001b[39m+\u001b[39m short_feature_cols))\n",
      "\u001b[1;32m/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb Zelle 2\u001b[0m in \u001b[0;36mrun_training_phase\u001b[0;34m(asset, method, price_data)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m bet_sizing \u001b[39m=\u001b[39m get_bet_sizing(method, past_returns)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m strategy \u001b[39m=\u001b[39m TradingStrategy(price_data, asset\u001b[39m.\u001b[39mvalue, bet_sizing, method)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m strategy\u001b[39m.\u001b[39;49mgenerate_signals()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m strategy\u001b[39m.\u001b[39msimulate_trades()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuelheeren/Documents/Masterarbeit/MA/meta_evaluation_backtest.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m trade_df \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39mget_trade_data()\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/MA/new_strategy.py:235\u001b[0m, in \u001b[0;36mTradingStrategy.generate_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m session_start \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mindex:\n\u001b[1;32m    234\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m prev_close \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_previous_session_close(session_start, session)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prev_close:\n\u001b[1;32m    237\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/MA/new_strategy.py:364\u001b[0m, in \u001b[0;36mTradingStrategy._get_previous_session_close\u001b[0;34m(self, current_time, session)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_previous_session_close\u001b[39m(\u001b[39mself\u001b[39m, current_time: pd\u001b[39m.\u001b[39mTimestamp, session: SessionTime) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    360\u001b[0m     prev_close_time \u001b[39m=\u001b[39m (current_time\u001b[39m.\u001b[39mnormalize() \u001b[39m-\u001b[39m pd\u001b[39m.\u001b[39mTimedelta(days\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mreplace(\n\u001b[1;32m    361\u001b[0m         hour\u001b[39m=\u001b[39msession\u001b[39m.\u001b[39mclose\u001b[39m.\u001b[39mhour,\n\u001b[1;32m    362\u001b[0m         minute\u001b[39m=\u001b[39msession\u001b[39m.\u001b[39mclose\u001b[39m.\u001b[39mminute\n\u001b[1;32m    363\u001b[0m     )\n\u001b[0;32m--> 364\u001b[0m     prev_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mindex \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m prev_close_time]\n\u001b[1;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m prev_data\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prev_data\u001b[39m.\u001b[39mempty \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3495\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[1;32m   3498\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3499\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3500\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3551\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3549\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n\u001b[1;32m   3550\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3708\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   3709\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3710\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3714\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3717\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3718\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3699\u001b[0m nv\u001b[39m.\u001b[39mvalidate_take((), kwargs)\n\u001b[1;32m   3701\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3703\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3704\u001b[0m     indices, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis), verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   3705\u001b[0m )\n\u001b[1;32m   3706\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:900\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    897\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[1;32m    899\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 900\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m    901\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[1;32m    902\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[1;32m    903\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    904\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    905\u001b[0m     consolidate\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    906\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:692\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    686\u001b[0m         indexer,\n\u001b[1;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[1;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m    693\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[1;32m    694\u001b[0m             indexer,\n\u001b[1;32m    695\u001b[0m             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    696\u001b[0m             fill_value\u001b[39m=\u001b[39m(\n\u001b[1;32m    697\u001b[0m                 fill_value \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m blk\u001b[39m.\u001b[39mfill_value\n\u001b[1;32m    698\u001b[0m             ),\n\u001b[1;32m    699\u001b[0m         )\n\u001b[1;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    701\u001b[0m     ]\n\u001b[1;32m    703\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m    704\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:693\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    686\u001b[0m         indexer,\n\u001b[1;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[1;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 693\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m    694\u001b[0m             indexer,\n\u001b[1;32m    695\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    696\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    697\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n\u001b[1;32m    698\u001b[0m             ),\n\u001b[1;32m    699\u001b[0m         )\n\u001b[1;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    701\u001b[0m     ]\n\u001b[1;32m    703\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m    704\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/blocks.py:1137\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m   1138\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[1;32m   1139\u001b[0m )\n\u001b[1;32m   1141\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[39m#  this assertion\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m new_mgr_locs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/array_algos/take.py:163\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[1;32m    162\u001b[0m )\n\u001b[0;32m--> 163\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m flip_order:\n\u001b[1;32m    166\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def split_price_data(price_data: pd.DataFrame, split_ratio: float = 0.7):\n",
    "    split_idx = int(len(price_data) * split_ratio)\n",
    "    return price_data.iloc[:split_idx], price_data.iloc[split_idx:]\n",
    "\n",
    "def run_training_phase(asset: Asset, method: BetSizingMethod, price_data: pd.DataFrame):\n",
    "    # Run base strategy\n",
    "    past_returns = price_data['close'].pct_change().dropna()\n",
    "    bet_sizing = get_bet_sizing(method, past_returns)\n",
    "    \n",
    "    strategy = TradingStrategy(price_data, asset.value, bet_sizing, method)\n",
    "    strategy.generate_signals()\n",
    "    strategy.simulate_trades()\n",
    "    \n",
    "    trade_df = strategy.get_trade_data()\n",
    "    labeled = generate_meta_labeled_data(trade_df)\n",
    "    #labeled_with_features = merge_with_raw_features(labeled, asset.value)\n",
    "    labeled_with_features = labeled\n",
    "    \n",
    "    print(labeled_with_features.columns)\n",
    "    return labeled_with_features\n",
    "\n",
    "def train_meta_model(train_df: pd.DataFrame, long_feature_cols: list, short_feature_cols: list) -> MetaModelHandler:\n",
    "    model = MetaModelHandler()\n",
    "    model.train(train_df, long_feature_cols, short_feature_cols)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_parallel_evaluation(asset, method, test_price_data, signals, meta_model, feature_cols):\n",
    "    past_returns = test_price_data['close'].pct_change().dropna()\n",
    "    bet_sizing = get_bet_sizing(method, past_returns)\n",
    "\n",
    "    #  First, initialize Meta strategy to access feature-enriched data\n",
    "    meta_strategy = MetaLabelingStrategy(\n",
    "        test_price_data.copy(), asset.value, bet_sizing, method,\n",
    "        meta_model_handler=meta_model\n",
    "    )\n",
    "    feature_data = meta_strategy.data.copy()\n",
    "\n",
    "    #  Use feature_data for both strategies\n",
    "    baseline = TradingStrategy(feature_data.copy(), asset.value, bet_sizing, method)\n",
    "    baseline.trade_signals = signals\n",
    "\n",
    "    filtered = MetaLabelingStrategy(feature_data.copy(), asset.value, bet_sizing, method, meta_model_handler=meta_model,feature_cols=feature_cols)\n",
    "    filtered.trade_signals = signals\n",
    "\n",
    "    print(\"\\n📊 Baseline features in .data:\")\n",
    "    print(baseline.data.columns.tolist())\n",
    "\n",
    "    print(\"\\n📊 Filtered features in .data:\")\n",
    "    print(filtered.data.columns.tolist())\n",
    "    print(\"\\n🕒 Baseline index:\", baseline.data.index.name, baseline.data.index.dtype)\n",
    "    print(\"🕒 Filtered index:\", filtered.data.index.name, filtered.data.index.dtype)\n",
    "\n",
    "    baseline.simulate_trades()\n",
    "    filtered.simulate_trades()\n",
    "\n",
    "    return baseline, filtered\n",
    "\n",
    "\n",
    "def compare_backtests(baseline: TradingStrategy, filtered: MetaLabelingStrategy, asset: Asset, method: BetSizingMethod):\n",
    "    def capture_regime_stats(strategy, name):\n",
    "        buffer = io.StringIO()\n",
    "        sys.stdout = buffer\n",
    "        print(f\"\\n🔹 {name} Strategy:\")\n",
    "\n",
    "        df = strategy.get_trade_data()\n",
    "\n",
    "        if 'regime_label' not in df.columns or 'pnl' not in df.columns:\n",
    "            print(\"Required columns not found in trade data.\")\n",
    "        else:\n",
    "            grouped = df.groupby('regime_label')\n",
    "\n",
    "            for regime, group in grouped:\n",
    "                trades = len(group)\n",
    "                avg_pnl = group['pnl'].mean()\n",
    "                total_pnl = group['pnl'].sum()\n",
    "                wins = (group['pnl'] > 0).sum()\n",
    "                winrate = wins / trades if trades > 0 else 0\n",
    "\n",
    "                print(f\"  {regime}: Trades = {trades}, \"\n",
    "                      f\"Avg PnL = {avg_pnl:.2f}, Total PnL = {total_pnl:.2f}, \"\n",
    "                      f\"Win Rate = {winrate:.2%}\")\n",
    "\n",
    "        sys.stdout = sys.__stdout__\n",
    "        return buffer.getvalue()\n",
    "    \n",
    "    print(\"\\n[BASELINE]\")\n",
    "    baseline_bt = Backtest(baseline)\n",
    "    baseline_bt.run_analysis()\n",
    "    baseline_buffer = io.StringIO()\n",
    "    sys.stdout = baseline_buffer\n",
    "    baseline_bt.print_summary()\n",
    "    sys.stdout = sys.__stdout__\n",
    "    baseline_summary = baseline_buffer.getvalue()\n",
    "    print(baseline_summary)\n",
    "\n",
    "    print(\"\\n[META-FILTERED]\")\n",
    "    filtered_bt = Backtest(filtered)\n",
    "    filtered_bt.run_analysis()\n",
    "    filtered_buffer = io.StringIO()\n",
    "    sys.stdout = filtered_buffer\n",
    "    filtered_bt.print_summary()\n",
    "    sys.stdout = sys.__stdout__\n",
    "    filtered_summary = filtered_buffer.getvalue()\n",
    "    print(filtered_summary)\n",
    "\n",
    "    print(f\"\\nTrades Rejected by Meta-Model: {filtered.rejected_trades}\")\n",
    "\n",
    "    output_dir = \"results_metalabel\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    asset_name = asset.value.lower()\n",
    "    method_name = method.value.lower()\n",
    "\n",
    "    baseline_csv = f\"baseline_{asset_name}_{method_name}.csv\"\n",
    "    filtered_csv = f\"filtered_{asset_name}_{method_name}.csv\"\n",
    "    baseline_txt = f\"baseline_{asset_name}_{method_name}.txt\"\n",
    "    filtered_txt = f\"filtered_{asset_name}_{method_name}.txt\"\n",
    "\n",
    "    baseline.get_trade_data().to_csv(os.path.join(output_dir, baseline_csv), index=False)\n",
    "    filtered.get_trade_data().to_csv(os.path.join(output_dir, filtered_csv), index=False)\n",
    "\n",
    "    with open(os.path.join(output_dir, baseline_txt), \"w\") as f:\n",
    "        f.write(baseline_summary)\n",
    "\n",
    "    with open(os.path.join(output_dir, filtered_txt), \"w\") as f:\n",
    "        f.write(filtered_summary)\n",
    "    \n",
    "        # Run and print regime comparisons\n",
    "    print(\"\\n📈 Regime Comparison\")\n",
    "    regime_baseline = capture_regime_stats(baseline, \"Baseline\")\n",
    "    regime_filtered = capture_regime_stats(filtered, \"Meta-Filtered\")\n",
    "\n",
    "    print(regime_baseline)\n",
    "    print(regime_filtered)\n",
    "\n",
    "    # Append to the already existing summary files\n",
    "    with open(baseline_txt, \"a\") as f:\n",
    "        f.write(\"\\n\\n=== Regime Analysis ===\\n\")\n",
    "        f.write(regime_baseline)\n",
    "\n",
    "    with open(filtered_txt, \"a\") as f:\n",
    "        f.write(\"\\n\\n=== Regime Analysis ===\\n\")\n",
    "        f.write(regime_filtered)\n",
    "\n",
    "    print(f\"\\n✅ CSVs saved to: {output_dir}\")\n",
    "    print(f\" - {baseline_csv}\")\n",
    "    print(f\" - {filtered_csv}\")\n",
    "    print(f\"\\n✅ Summaries saved to:\")\n",
    "    print(f\" - {baseline_txt}\")\n",
    "    print(f\" - {filtered_txt}\")\n",
    "\n",
    "def evaluate_backtest_and_regimes(\n",
    "    baseline_path: str,\n",
    "    filtered_path: str,\n",
    "    txt_output_path: str = \"results_metalabel/comparison/evaluation_summary.txt\"\n",
    "):\n",
    "    buffer = io.StringIO()\n",
    "    sys.stdout = buffer  # Redirect print to buffer\n",
    "\n",
    "    print(\"\\n📊 Evaluation from Final CSVs\")\n",
    "\n",
    "    def compute_backtest_kpis(df: pd.DataFrame, label: str):\n",
    "        print(f\"\\n📈 {label} Backtest Summary (Per Session Evaluation)\")\n",
    "\n",
    "        df = df[df['position_size'] > 0]\n",
    "\n",
    "        if 'pnl' not in df.columns or 'session' not in df.columns:\n",
    "            print(\"❌ Missing required columns ('pnl', 'session').\")\n",
    "            return\n",
    "\n",
    "        session_stats = []\n",
    "\n",
    "        for session, group in df.groupby(\"session\"):\n",
    "            group = group.sort_values(\"exit_time\")\n",
    "\n",
    "            if group.empty:\n",
    "                continue\n",
    "\n",
    "            # Build capital curve on actual trade exits\n",
    "            capital = 100_000  # consistent with old method\n",
    "            capital_curve = []\n",
    "\n",
    "            for pnl in group['pnl']:\n",
    "                capital += pnl\n",
    "                capital_curve.append(capital)\n",
    "\n",
    "            group = group.copy()\n",
    "            group['capital_curve'] = capital_curve\n",
    "            returns = pd.Series(capital_curve).pct_change().dropna()\n",
    "\n",
    "            # Sharpe: based on trading days only\n",
    "            if len(returns) >= 2:\n",
    "                mean_return = returns.mean()\n",
    "                vol = returns.std()\n",
    "                sharpe = (mean_return / vol) * np.sqrt(252) if vol > 0 else 0\n",
    "            else:\n",
    "                sharpe = 0\n",
    "\n",
    "            # Max drawdown from capital curve\n",
    "            cumulative = pd.Series(capital_curve).cummax()\n",
    "            drawdown = (cumulative - capital_curve) / cumulative\n",
    "            max_drawdown = drawdown.max()\n",
    "\n",
    "            wins = (group['pnl'] > 0).sum()\n",
    "            losses = (group['pnl'] <= 0).sum()\n",
    "            win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "\n",
    "            total_pnl = group[\"pnl\"].sum()\n",
    "            final_capital = capital_curve[-1]\n",
    "\n",
    "            session_stats.append({\n",
    "                \"session\": session,\n",
    "                \"total_pnl\": total_pnl,\n",
    "                \"final_capital\": final_capital,\n",
    "                \"win_rate\": win_rate,\n",
    "                \"sharpe\": sharpe,\n",
    "                \"max_drawdown\": max_drawdown,\n",
    "                \"trades\": len(group)\n",
    "            })\n",
    "\n",
    "            print(f\"\\n🔹 Session: {session}\")\n",
    "            print(f\"  Final Capital: ${final_capital:,.2f}\")\n",
    "            print(f\"  Total PnL:     ${total_pnl:,.2f}\")\n",
    "            print(f\"  Win Rate:      {win_rate:.2%} ({wins}W / {losses}L)\")\n",
    "            print(f\"  Max Drawdown:  {max_drawdown:.2%}\")\n",
    "            print(f\"  Sharpe Ratio:  {sharpe:.2f}\")\n",
    "            print(f\"  Total Trades:  {len(group)}\")\n",
    "\n",
    "        # Optional combined stats\n",
    "        combined_pnl = sum(s[\"total_pnl\"] for s in session_stats)\n",
    "        print(f\"\\n📊 Combined PnL across all sessions: ${combined_pnl:,.2f}\")\n",
    "\n",
    "\n",
    "    def compute_regime_stats(df: pd.DataFrame, label: str):\n",
    "        print(f\"\\n📊 {label} Regime Breakdown by Session\")\n",
    "\n",
    "        if \"regime_label\" not in df.columns or \"pnl\" not in df.columns or \"session\" not in df.columns:\n",
    "            print(\"❌ Missing required columns ('regime_label', 'pnl', or 'session').\")\n",
    "            return\n",
    "\n",
    "        session_groups = df.groupby(\"session\")\n",
    "        for session, session_df in session_groups:\n",
    "            print(f\"\\n🔹 Session: {session}\")\n",
    "            regime_groups = session_df.groupby(\"regime_label\")\n",
    "            for regime, group in regime_groups:\n",
    "                trades = len(group)\n",
    "                avg_pnl = group[\"pnl\"].mean()\n",
    "                total_pnl = group[\"pnl\"].sum()\n",
    "                wins = (group[\"pnl\"] > 0).sum()\n",
    "                win_rate = wins / trades if trades > 0 else 0\n",
    "\n",
    "                print(f\"  - Regime: {regime}\")\n",
    "                print(f\"    Trades:    {trades}\")\n",
    "                print(f\"    Avg PnL:   ${avg_pnl:.2f}\")\n",
    "                print(f\"    Total PnL: ${total_pnl:.2f}\")\n",
    "                print(f\"    Win Rated:  {win_rate:.2%}\")\n",
    "\n",
    "\n",
    "    # === Load CSVs ===\n",
    "    baseline_df = pd.read_csv(baseline_path, parse_dates=[\"entry_time\", \"exit_time\"])\n",
    "    filtered_df = pd.read_csv(filtered_path, parse_dates=[\"entry_time\", \"exit_time\"])\n",
    "\n",
    "    # === Compute Metrics ===\n",
    "    compute_backtest_kpis(baseline_df, \"Baseline\")\n",
    "    compute_regime_stats(baseline_df, \"Baseline\")\n",
    "\n",
    "    compute_backtest_kpis(filtered_df, \"Meta-Filtered\")\n",
    "    compute_regime_stats(filtered_df, \"Meta-Filtered\")\n",
    "\n",
    "    # === Write output to TXT file ===\n",
    "    sys.stdout = sys.__stdout__  # Restore stdout\n",
    "    with open(txt_output_path, \"w\") as f:\n",
    "        f.write(buffer.getvalue())\n",
    "\n",
    "    print(f\"\\n✅ Full evaluation written to: {txt_output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    asset = Asset.GAS\n",
    "    method = BetSizingMethod.FIXED\n",
    "\n",
    "    long_feature_cols = [\"drawdown_30\", \"atr_14\", \"ma_14\", \"avg_return_30d\", \"daily_return\", \"vix_close\", \"session_code\"]\n",
    "    short_feature_cols = [\"drawdown_30\", \"daily_volatility\", \"vix_close\", \"rolling_f1\", \"t10yie\", \"day_of_week\", \"dgs10\"]\n",
    "\n",
    "    price_path = Path(f\"data/processed/{asset.value}/combined_data.csv\")\n",
    "    price_data = pd.read_csv(price_path, index_col='timestamp', parse_dates=True)\n",
    "\n",
    "    # Split\n",
    "    train_data, test_data = split_price_data(price_data)\n",
    "\n",
    "    # Training\n",
    "    train_trades = run_training_phase(asset, method, train_data)\n",
    "    \n",
    "    #clean_features = train_trades[feature_cols].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    #train_trades_cleaned = train_trades.loc[clean_features.index]\n",
    "    all_features = list(set(long_feature_cols + short_feature_cols))\n",
    "    train_trades_cleaned = train_trades.replace([np.inf, -np.inf], np.nan).dropna(subset=all_features)\n",
    "\n",
    "\n",
    "    train_trades_cleaned.to_csv(\"results_metalabel/train_data_debug.csv\", index=False)\n",
    "    print(\"✅ Training data saved to results_metalabel/train_data_debug.csv\")\n",
    "\n",
    "    meta_model = train_meta_model(train_trades_cleaned, long_feature_cols, short_feature_cols)\n",
    "\n",
    "    # Reuse signals\n",
    "    signal_gen = TradingStrategy(test_data.copy(), asset.value, get_bet_sizing(method), method)\n",
    "    signal_gen.generate_signals()\n",
    "    shared_signals = signal_gen.trade_signals\n",
    "\n",
    "    print(\"\\n🔍 Entry Time Check (from shared_signals dict):\")\n",
    "    print(\"Type:\", type(shared_signals))\n",
    "    print(\"Keys in shared_signals:\", list(shared_signals.keys()))\n",
    "\n",
    "    # Try to peek at the first signal (depending on structure)\n",
    "    first_key = next(iter(shared_signals))\n",
    "    first_signal_list = shared_signals[first_key]\n",
    "    first_signal = first_signal_list[0]  # Get the first signal from the list\n",
    "    print(\"Type of entry_time:\", type(first_signal['entry_time']))\n",
    "\n",
    "    # Evaluation\n",
    "    base_strat, filtered_strat = run_parallel_evaluation(\n",
    "        asset, method, test_data, shared_signals, meta_model, all_features\n",
    "    )\n",
    "\n",
    "    # Compare\n",
    "    compare_backtests(base_strat, filtered_strat, asset, method)\n",
    "    evaluate_backtest_and_regimes(\n",
    "    baseline_path=f\"results_metalabel/baseline_{asset.value.lower()}_{method.value.lower()}.csv\",\n",
    "    filtered_path=f\"results_metalabel/filtered_{asset.value.lower()}_{method.value.lower()}.csv\",\n",
    "    txt_output_path=f\"results_metalabel/comparison/evaluation_{asset.value.lower()}_{method.value.lower()}.txt\"\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4131570aad7ff77d93c6be89cfb61a61d96547c15666b9d6a932bac1ad3bd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
